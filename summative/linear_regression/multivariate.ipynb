{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a0b1b9",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "# CalmPulse Rating Forecast Notebook\n",
    "\n",
    "Mission: Help the CalmPulse wellbeing mobile app team forecast App Store ratings for meditation and focus companions so we can prioritize UX investments that grow retention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24680314",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "### Dataset overview\n",
    "- **Source:** Apple Search API (iTunes Software entity) for meditation/focus keywords harvested in Oct 2024.\n",
    "- **Rows:** 1,077 wellbeing/productivity iOS apps.\n",
    "- **Target:** `avg_rating` (1–5) from the live store listing.\n",
    "- **Features:** Pricing, engagement (rating_count, size_mb), monetization flags, localization breadth, update cadence.\n",
    "- **Mission fit:** CalmPulse prioritizes meditation/focus companions with reliable ratings signals so product can invest in the stickiest feature sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f7ed3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for path in [start, *start.parents]:\n",
    "        if (path / '.git').exists() or (path / 'summative').exists():\n",
    "            return path\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "NOTEBOOK_DIR = PROJECT_ROOT / 'summative' / 'linear_regression'\n",
    "DATA_DIR = NOTEBOOK_DIR / 'data'\n",
    "MODELS_DIR = NOTEBOOK_DIR / 'models'\n",
    "REPORTS_DIR = NOTEBOOK_DIR / 'reports'\n",
    "DATA_PATH = DATA_DIR / 'mindful_app_store.csv'\n",
    "\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "REPORTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print('Using project root:', PROJECT_ROOT)\n",
    "print('Using data from:', DATA_PATH)\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "print('Raw shape:', raw_df.shape)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9b86e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "raw_df.describe(include='all').transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e92c2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.histplot(raw_df['avg_rating'], bins=30, ax=axes[0], color='teal')\n",
    "axes[0].set_title('Distribution of Average Ratings')\n",
    "axes[0].set_xlabel('Average Rating (1-5)')\n",
    "axes[0].axvline(raw_df['avg_rating'].median(), color='orange', linestyle='--', label='Median')\n",
    "axes[0].legend()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=raw_df,\n",
    "    x=np.log1p(raw_df['rating_count']),\n",
    "    y='avg_rating',\n",
    "    hue='has_iap',\n",
    "    alpha=0.5,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title('Engagement vs Rating (log scale)')\n",
    "axes[1].set_xlabel('log(1 + Rating Count)')\n",
    "axes[1].set_ylabel('Average Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "numeric_cols = ['price', 'rating_count', 'size_mb', 'language_count', 'age_days', 'update_recency_days']\n",
    "corr = raw_df[numeric_cols + ['avg_rating']].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2230eb",
   "metadata": {},
   "source": [
    "### Quick takeaways from the raw data\n",
    "- Ratings are tightly clustered between 4.0–4.8 with a long right tail, so small RMSE deltas matter.\n",
    "- Engagement (`rating_count`) has a weak positive relationship with rating once we log-scale it; monetization flag (`has_iap`) separates slightly higher performers.\n",
    "- Update cadence (`update_recency_days`) and localization breadth (`language_count`) have the strongest numeric correlation with `avg_rating`, guiding which columns to treat as high-signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f4472",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def parse_min_ios(value):\n",
    "    if value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "        return np.nan\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    text = str(value).split(' ')[0]\n",
    "    try:\n",
    "        return float(text)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df = df.dropna(subset=[\n",
    "        'avg_rating', 'price', 'rating_count', 'size_mb', 'primary_genre',\n",
    "        'content_rating', 'language_count', 'age_days', 'update_recency_days'\n",
    "    ])\n",
    "    df = df[df['avg_rating'].between(1, 5)]\n",
    "    df = df[df['rating_count'] > 0]\n",
    "    df['min_ios_numeric'] = df['min_ios'].apply(parse_min_ios)\n",
    "    df['min_ios_numeric'] = df['min_ios_numeric'].fillna(df['min_ios_numeric'].median())\n",
    "    df['log_rating_count'] = np.log1p(df['rating_count'])\n",
    "    df = df.drop_duplicates(subset=['app_name'])\n",
    "    return df\n",
    "\n",
    "clean_df = engineer_features(raw_df)\n",
    "print('Engineered shape:', clean_df.shape)\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf68e7d",
   "metadata": {},
   "source": [
    "### Feature engineering notes\n",
    "- Drop incomplete rows on the strongest predictors (rating_count, size, price) to avoid training noise.\n",
    "- Clamp the target to [1,5] and require at least one rating to mimic App Store ranking rules.\n",
    "- Parse the `min_ios` string into a numeric feature and log-scale rating_count; both transformations line up with how we expect experience quality to shift.\n",
    "- Deduplicate by `app_name` so heavy hitters do not leak across splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4764d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "target = clean_df['avg_rating']\n",
    "feature_df = clean_df.drop(columns=['avg_rating', 'app_name'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=pd.qcut(target, q=4, duplicates='drop'),\n",
    ")\n",
    "print('Train/Test split:', X_train.shape, X_test.shape)\n",
    "\n",
    "numeric_features = [\n",
    "    'price', 'rating_count', 'size_mb', 'language_count', 'has_iap', 'has_support_url',\n",
    "    'is_game_center', 'age_days', 'update_recency_days', 'min_ios_numeric'\n",
    "]\n",
    "categorical_features = ['primary_genre', 'content_rating']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([('scaler', StandardScaler())]), numeric_features),\n",
    "    ('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), categorical_features),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b20768",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "trained_pipelines = {}\n",
    "base_models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(max_depth=8, min_samples_leaf=5, random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "}\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds_train = pipeline.predict(X_train)\n",
    "    preds_test = pipeline.predict(X_test)\n",
    "    metrics = {\n",
    "        'model': name,\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, preds_train)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, preds_test)),\n",
    "        'test_mae': mean_absolute_error(y_test, preds_test),\n",
    "        'test_r2': r2_score(y_test, preds_test),\n",
    "    }\n",
    "    results.append(metrics)\n",
    "    trained_pipelines[name] = pipeline\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values('test_rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3accc06",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sgd = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SGDRegressor(\n",
    "        loss='squared_error',\n",
    "        penalty=None,\n",
    "        max_iter=1,\n",
    "        learning_rate='constant',\n",
    "        eta0=0.01,\n",
    "        random_state=42,\n",
    "        warm_start=True,\n",
    "        tol=None,\n",
    "    )),\n",
    "])\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "EPOCHS = 80\n",
    "for _ in range(EPOCHS):\n",
    "    sgd.fit(X_train, y_train)\n",
    "    train_losses.append(mean_squared_error(y_train, sgd.predict(X_train)))\n",
    "    test_losses.append(mean_squared_error(y_test, sgd.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label='Train MSE')\n",
    "plt.plot(test_losses, label='Test MSE')\n",
    "plt.title('SGD Gradient Descent Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'loss_curve.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "sgd_metrics = {\n",
    "    'model': 'SGDRegressor',\n",
    "    'train_rmse': np.sqrt(train_losses[-1]),\n",
    "    'test_rmse': np.sqrt(test_losses[-1]),\n",
    "    'test_mae': mean_absolute_error(y_test, sgd.predict(X_test)),\n",
    "    'test_r2': r2_score(y_test, sgd.predict(X_test)),\n",
    "}\n",
    "results.append(sgd_metrics)\n",
    "trained_pipelines['SGDRegressor'] = sgd\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce97b8",
   "metadata": {},
   "source": [
    "### Model comparison\n",
    "- **Random Forest** generalizes best with ~0.27 RMSE and ~0.20 MAE, handling the mild non-linearity between engagement and ratings.\n",
    "- **Linear Regression** underfits (higher bias, negative R²) once categorical one-hot encoding explodes the feature space.\n",
    "- **Decision Tree** overfits the training split despite depth limits, so we prefer the ensemble’s smoother residuals.\n",
    "- **SGD (gradient descent)** converges slowly but provides the required loss-curve artifact for Task 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae23e3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = clean_df['log_rating_count']\n",
    "y = clean_df['avg_rating']\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "x_line = np.linspace(x.min(), x.max(), 200)\n",
    "y_line = slope * x_line + intercept\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, alpha=0.35, label='Actual Apps', color='teal')\n",
    "plt.plot(x_line, y_line, color='darkorange', linewidth=2.5, label='Linear Fit')\n",
    "plt.xlabel('log(1 + Rating Count)')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Scatter Plot with Regression Line')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'rating_line_fit.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc0121",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "metrics_path = REPORTS_DIR / 'model_metrics.json'\n",
    "with metrics_path.open('w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "best_model = min(results, key=lambda m: m['test_rmse'])\n",
    "joblib.dump(\n",
    "    {\n",
    "        'pipeline': trained_pipelines[best_model['model']],\n",
    "        'metrics': best_model,\n",
    "        'feature_columns': list(feature_df.columns),\n",
    "    },\n",
    "    MODELS_DIR / 'best_model.joblib',\n",
    ")\n",
    "print('Best model:', best_model)\n",
    "print('Artifacts saved to:', MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f762d1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def predict_rating(payload: dict) -> float:\n",
    "    artifact = joblib.load(MODELS_DIR / 'best_model.joblib')\n",
    "    pipeline = artifact['pipeline']\n",
    "    df = pd.DataFrame([payload]).copy()\n",
    "    df['min_ios_numeric'] = df['min_ios'].apply(parse_min_ios)\n",
    "    df['min_ios_numeric'] = df['min_ios_numeric'].fillna(df['min_ios_numeric'].median())\n",
    "    df['log_rating_count'] = np.log1p(df['rating_count'])\n",
    "    for col in artifact['feature_columns']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    df = df.reindex(columns=artifact['feature_columns'], fill_value=0)\n",
    "    return float(pipeline.predict(df)[0])\n",
    "\n",
    "sample_app = {\n",
    "    'price': 0.0,\n",
    "    'rating_count': 3500,\n",
    "    'size_mb': 110.0,\n",
    "    'primary_genre': 'Health & Fitness',\n",
    "    'content_rating': '4+',\n",
    "    'language_count': 12,\n",
    "    'has_iap': 1,\n",
    "    'has_support_url': 1,\n",
    "    'min_ios': '13.0',\n",
    "    'is_game_center': 0,\n",
    "    'age_days': 2200,\n",
    "    'update_recency_days': 30,\n",
    "}\n",
    "\n",
    "predict_rating(sample_app)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
